# K-means Text Clustering

This repository contains a working notebook for applying **K-means clustering** to text data—designed for exploration, demonstration, and portfolio use by Chase Jamieson.

## Project Contents  
- `Final_Text_Clustering.ipynb` — The main notebook containing the full workflow: data ingestion, preprocessing, vectorization, clustering, and visualization.  

## Overview  
In this project I walk through:
1. Loading a text dataset (you could adapt to your own).  
2. Text preprocessing: tokenization, cleaning, stop-words removal, maybe stemming or lemmatization.  
3. Turning text into numerical form (e.g., TF-IDF or embeddings).  
4. Running the K‑means clustering algorithm to identify meaningful clusters of text documents.  
5. Visualizing and interpreting cluster results: what each cluster represents, how documents group, etc.  
6. Reflecting on strengths, limitations, and possible next steps (different clustering algorithms, dimensionality reduction, deeper semantic features, etc.).

## Tools & Technologies  
- Python (3.x)  
- Jupyter / Colab notebook  
- Major libraries: `pandas`, `numpy`, `scikit-learn`, `matplotlib` / `seaborn`, `nltk` (or `spaCy`) — depending on your specific stack.  

